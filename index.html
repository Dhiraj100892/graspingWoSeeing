<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Dex-Net by BerkeleyAutomation</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    </head>
  <body>
    <div class="wrapper">
      <header>
        <h1 class="header"><a href="https://dhiraj100892.github.io/graspingWoSeeing/">Grasping Without Seeing</a></h1>
        <p class="header"></p>

        <h2 class="header"><a href="https://dhiraj100892.github.io/graspingWoSeeing/">ArXiv</a></h2>
        <p class="header"></p>

        <h2 class="header"><a href="https://dhiraj100892.github.io/graspingWoSeeing/">Code</a></h2>
        <p class="header"></p>
	
       	<h2 class="header"><a href="https://dhiraj100892.github.io/graspingWoSeeing/">Data</a></h2>
        <p class="header"></p>

      </header>

      <section>
      <html>
      <body>
	<iframe width="620" height="340" src="https://www.youtube.com/embed/iCQsM7EE4HI" frameborder="0" allowfullscreen></iframe>
      </body>
      </html>
      <p>
      The Dexterity Network (Dex-Net) is a research project including code, datasets, and algorithms for generating datasets of synthetic point clouds, robot parallel-jaw grasps and metrics of grasp robustness based on physics for thousands of 3D object models to train machine learning-based methods to plan robot grasps.
      The broader goal of the Dex-Net project is to develop highly reliable robot grasping across a wide variety of rigid objects such as tools, household items, packaged goods, and industrial parts.
      </p>
      <p>
      <a href="#dexnet_2">Dex-Net 2.0</a> is designed to generated training datasets to learn Grasp Quality Convolutional Neural Networks (GQ-CNN) models that predict the probability of success of candidate parallel-jaw grasps on objects from point clouds.
      GQ-CNNs may be useful for quickly planning grasps that can lift and transport a wide variety of objects a physical robot.
      <a href="#dexnet_21">Dex-Net 2.1</a> adds dynamic simulation with <a href="https://pypi.python.org/pypi/pybullet">pybullet</a> and extends the robust grasping model to the sequential task of bin picking.
      <a href="#dexnet_3">Dex-Net 3.0</a> adds support for suction-based end-effectors.
      <a href="#dexnet_1">Dex-Net 1.0</a> was designed for distributed robust grasp analysis in the Cloud across datasets of over 10,000 3D mesh models.
      </p>
      <p>
      The project was created by <a href="http://www.jeff-mahler.com">Jeff Mahler</a> and <a href="http://goldberg.berkeley.edu">Prof. Ken Goldberg</a> and is currently maintained by the <a href="http://autolab.berkeley.edu/">Berkeley AUTOLAB</a>.
      For more info, <a href="#contact">contact us</a>.      
      </p>

      <h2 class="header" id="links" ><font color="black">Project Links</font></h2>
      <p>

      <h3 class="header" id="links" ><font color="black">Datasets</font></h3>
      <ul>
      <li> <a href="http://bit.ly/2rIM7Jk">GQ-CNN Training Datasets</a> </li>
      <li> <a href="http://bit.ly/2tAFMko">Pre-trained GQ-CNN Models</a> </li>
      <li> <a href="http://bit.ly/2tLnRrQ">Object Mesh Dataset v1.1</a> </li>
      <li> <a href="http://bit.ly/2vb3OCz">HDF5 Database of 3D Objects, Parallel-Jaw Grasps for YuMi, and Robustness Metrics</a> </li>
      </ul>

      <h3 class="header" id="links" ><font color="black">Code</font></h3>
      <ul>
      <li> <a href="https://github.com/BerkeleyAutomation/gqcnn">GQ-CNN Python Training Code</a> (<a href="https://berkeleyautomation.github.io/gqcnn">Documentation</a>)</li>
      <li> <a href="https://github.com/BerkeleyAutomation/dex-net">Dex-Net Database Python API</a> (<a href="https://berkeleyautomation.github.io/dex-net/code.html">Documentation</a>)</li>
      </ul>

      <h3 class="header" id="links" ><font color="black">Other</font></h3>
      <ul>
      <li> <a href="http://bair.berkeley.edu/blog/2017/06/27/dexnet-2.0/">BAIR Blog Post</a> </li>
      <li> <a href="http://autolab.berkeley.edu">Berkeley AUTOLAB</a> </li>
      </ul>
      </p>

      <h2 class="header" id="contact"><font color="black">Contributors</font></h2>

      <a href="http://adithyamurali.com/">Adithya Murali</a>, Matt Matl, Bill DeRose, Jacky Liang, Alan Li, Vishal Satish, and <a href="http://goldberg.berkeley.edu">Ken Goldberg</a>.</p>

      <p>Past contributors include:<br>
      <a href="http://www.cs.berkeley.edu/~ftpokorny/">Florian Pokorny</a>, Brian Hou, Sherdil Niyaz, Xinyu Liu, Melrose Roderkick, <a href="http://imagine.enpc.fr/~aubrym/index.html">Mathieu Aubry</a>, Michael Laskey, Richard Doan, Brenton Chu, Raul Puri, Sahanna Suri, Nikhil Sharma, and Josh Price.</p>

      <h3>
      <a id="support-or-contact" class="anchor" href="#support-or-contact" aria-hidden="true"><span class="octicon octicon-link"></span></a>Support or Contact</h3>

      <p>Please Contact <a href="http://www.jeff-mahler.com">Jeff Mahler</a> (<a href="mailto:jmahler@berkeley.edu">email</a>) or <a href="goldberg.berkeley.edu">Prof. Ken Goldberg</a> (<a href="mailto:goldberg@berkeley.edu">email</a>) of the <a href="http://autolab.berkeley.edu/">AUTOLAB</a> at UC Berkeley.</p>
      </section>
    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
		
  </body>
</html>

